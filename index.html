<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Interface</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            max-width: 400px;
            width: 100%;
            text-align: center;
        }

        .mic-icon {
            width: 120px;
            height: 120px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 50%;
            display: flex;
            justify-content: center;
            align-items: center;
            margin: 0 auto 30px;
            cursor: pointer;
            transition: transform 0.3s ease;
        }

        .mic-icon:hover {
            transform: scale(1.05);
        }

        .mic-icon.recording {
            animation: pulse 1.5s infinite;
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        }

        .mic-icon.processing {
            animation: spin 2s linear infinite;
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
        }

        .mic-icon.playing {
            animation: pulse 1s infinite;
            background: linear-gradient(135deg, #FFA500 0%, #FF6347 100%);
        }

        @keyframes pulse {
            0%, 100% {
                transform: scale(1);
            }
            50% {
                transform: scale(1.1);
            }
        }

        @keyframes spin {
            0% {
                transform: rotate(0deg);
            }
            100% {
                transform: rotate(360deg);
            }
        }

        .mic-icon svg {
            width: 60px;
            height: 60px;
            fill: white;
        }

        .speaker-icon {
            width: 60px;
            height: 60px;
        }

        .btn {
            width: 100%;
            padding: 15px 30px;
            font-size: 16px;
            font-weight: 600;
            border: none;
            border-radius: 10px;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 10px 0;
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .btn-primary {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .btn-primary:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
        }

        .btn-success {
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            color: white;
        }

        .btn-success:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(17, 153, 142, 0.4);
        }

        .btn-danger {
            background: linear-gradient(135deg, #eb3349 0%, #f45c43 100%);
            color: white;
        }

        .btn-danger:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(235, 51, 73, 0.4);
        }

        .status {
            margin-top: 20px;
            padding: 10px;
            border-radius: 8px;
            font-size: 14px;
            font-weight: 500;
        }

        .status.info {
            background: #e3f2fd;
            color: #1976d2;
        }

        .status.success {
            background: #e8f5e9;
            color: #388e3c;
        }

        .status.error {
            background: #ffebee;
            color: #d32f2f;
        }

        .status.recording {
            background: #fff3e0;
            color: #f57c00;
        }

        .status.processing {
            background: #e0f7fa;
            color: #00796b;
        }

        .status.playing {
            background: #fff3e0;
            color: #FF6347;
        }

        .session-id {
            margin-top: 15px;
            font-size: 12px;
            color: #666;
            word-break: break-all;
        }

        .hidden {
            display: none;
        }

        h2 {
            color: #333;
            margin-bottom: 20px;
        }

        .response-text {
            margin-top: 20px;
            padding: 15px;
            background: #f5f5f5;
            border-radius: 10px;
            font-size: 14px;
            color: #333;
            max-height: 150px;
            overflow-y: auto;
            text-align: left;
        }
    </style>
</head>
<body>
    <div class="container">
        <div id="startScreen">
            <div class="mic-icon" id="micIcon">
                <svg viewBox="0 0 24 24">
                    <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
                    <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
                </svg>
            </div>
            <h2>Voice Interface</h2>
            <button class="btn btn-primary" id="startBtn">Start Conversation</button>
            <div class="session-id" id="sessionDisplay"></div>
        </div>

        <div id="recordingScreen" class="hidden">
            <div class="mic-icon recording" id="micIconRecording">
                <svg viewBox="0 0 24 24">
                    <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
                    <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
                </svg>
            </div>
            <h2>Recording...</h2>
            <button class="btn btn-success" id="sendVoiceBtn">Send Voice</button>
            <button class="btn btn-danger" id="endCallBtn">End Call</button>
            <div class="status recording" id="statusMsg">Listening to your voice...</div>
            <div class="session-id" id="sessionDisplayRecording"></div>
        </div>

        <div id="processingScreen" class="hidden">
            <div class="mic-icon processing" id="micIconProcessing">
                <svg viewBox="0 0 24 24">
                    <path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm-2 15l-5-5 1.41-1.41L10 14.17l7.59-7.59L19 8l-9 9z"/>
                </svg>
            </div>
            <h2>Processing...</h2>
            <div class="status processing">AI is thinking...</div>
            <div class="session-id" id="sessionDisplayProcessing"></div>
        </div>

        <div id="playingScreen" class="hidden">
            <div class="mic-icon playing" id="micIconPlaying">
                <svg viewBox="0 0 24 24" class="speaker-icon">
                    <path d="M3 9v6h4l5 5V4L7 9H3zm13.5 3c0-1.77-1.02-3.29-2.5-4.03v8.05c1.48-.73 2.5-2.25 2.5-4.02zM14 3.23v2.06c2.89.86 5 3.54 5 6.71s-2.11 5.85-5 6.71v2.06c4.01-.91 7-4.49 7-8.77s-2.99-7.86-7-8.77z"/>
                </svg>
            </div>
            <h2>Playing Response</h2>
            <div class="response-text" id="responseText"></div>
            <button class="btn btn-primary" id="continueBtn">Continue Conversation</button>
            <button class="btn btn-danger" id="endCallBtn2">End Call</button>
            <div class="session-id" id="sessionDisplayPlaying"></div>
        </div>

        <div class="status info hidden" id="mainStatus"></div>
    </div>

    <audio id="audioPlayer" style="display: none;"></audio>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let sessionId = '';
        const WEBHOOK_URL = 'https://devkhemani.app.n8n.cloud/webhook-test/voice-agent';

        // Generate unique session ID
        function generateSessionId() {
            return 'session_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
        }

        // Show status message
        function showStatus(message, type = 'info') {
            const status = document.getElementById('mainStatus');
            status.textContent = message;
            status.className = `status ${type}`;
            status.classList.remove('hidden');
            setTimeout(() => {
                status.classList.add('hidden');
            }, 3000);
        }

        // Show specific screen
        function showScreen(screenId) {
            document.getElementById('startScreen').classList.add('hidden');
            document.getElementById('recordingScreen').classList.add('hidden');
            document.getElementById('processingScreen').classList.add('hidden');
            document.getElementById('playingScreen').classList.add('hidden');
            document.getElementById(screenId).classList.remove('hidden');
        }

        // Update session display
        function updateSessionDisplay() {
            const sessionText = `Session ID: ${sessionId}`;
            document.getElementById('sessionDisplay').textContent = sessionText;
            document.getElementById('sessionDisplayRecording').textContent = sessionText;
            document.getElementById('sessionDisplayProcessing').textContent = sessionText;
            document.getElementById('sessionDisplayPlaying').textContent = sessionText;
        }

        // Start conversation
        document.getElementById('startBtn').addEventListener('click', async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 44100
                    } 
                });
                
                sessionId = generateSessionId();
                updateSessionDisplay();

                const mimeType = MediaRecorder.isTypeSupported('audio/webm') ? 'audio/webm' :
                                MediaRecorder.isTypeSupported('audio/mp4') ? 'audio/mp4' :
                                MediaRecorder.isTypeSupported('audio/ogg') ? 'audio/ogg' : '';
                
                if (!mimeType) {
                    showStatus('No supported audio format found', 'error');
                    return;
                }

                console.log('Using MIME type:', mimeType);

                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: mimeType
                });
                
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data && event.data.size > 0) {
                        console.log('Audio chunk received:', event.data.size, 'bytes');
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstart = () => {
                    console.log('Recording started');
                };

                mediaRecorder.onerror = (event) => {
                    console.error('MediaRecorder error:', event.error);
                    showStatus('Recording error', 'error');
                };

                mediaRecorder.start(1000);
                showScreen('recordingScreen');
                showStatus('Recording started', 'success');
            } catch (error) {
                showStatus('Microphone access denied', 'error');
                console.error('Error accessing microphone:', error);
            }
        });

        // Send voice
        document.getElementById('sendVoiceBtn').addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();

                mediaRecorder.onstop = async () => {
                    console.log('Recording stopped. Chunks:', audioChunks.length);
                    
                    if (audioChunks.length === 0) {
                        showStatus('No audio recorded', 'error');
                        return;
                    }

                    const audioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType });
                    console.log('Audio blob created:', audioBlob.size, 'bytes, type:', audioBlob.type);
                    
                    if (audioBlob.size === 0) {
                        showStatus('Empty audio recording', 'error');
                    } else {
                        // Stop microphone
                        mediaRecorder.stream.getTracks().forEach(track => track.stop());
                        
                        // Show processing screen
                        showScreen('processingScreen');
                        
                        // Send to webhook and wait for response
                        await sendToWebhook(audioBlob);
                    }
                    
                    audioChunks = [];
                };
            }
        });

        // Send audio to webhook
        async function sendToWebhook(audioBlob) {
            try {
                showStatus('Sending voice...', 'info');
                
                // Create FormData to send file
                const formData = new FormData();
                
                // Determine file extension
                const extension = audioBlob.type.includes('webm') ? 'webm' :
                                 audioBlob.type.includes('mp4') ? 'mp4' : 'ogg';
                
                // Create file from blob
                const audioFile = new File([audioBlob], `voice.${extension}`, {
                    type: audioBlob.type,
                    lastModified: Date.now()
                });
                
                formData.append('voice', audioFile);
                formData.append('sessionId', sessionId);
                formData.append('timestamp', new Date().toISOString());

                console.log('Sending to webhook...', {
                    size: audioBlob.size,
                    type: audioBlob.type,
                    sessionId: sessionId
                });

                const response = await fetch(WEBHOOK_URL, {
                    method: 'POST',
                    body: formData
                });

                console.log('Response status:', response.status);

                if (response.ok) {
                    // Check if response is audio
                    const contentType = response.headers.get('content-type');
                    
                    if (contentType && contentType.includes('audio')) {
                        // Get AI response text from header if available
                        const aiResponseText = response.headers.get('X-AI-Response') || 'AI is speaking...';
                        
                        // Get audio blob
                        const audioBlob = await response.blob();
                        console.log('Received audio response:', audioBlob.size, 'bytes');
                        
                        // Play audio
                        playAudioResponse(audioBlob, aiResponseText);
                    } else {
                        showStatus('Unexpected response format', 'error');
                        showScreen('startScreen');
                    }
                } else {
                    showStatus('Failed to get response', 'error');
                    console.error('Response status:', response.status);
                    showScreen('startScreen');
                }
            } catch (error) {
                showStatus('Error sending voice', 'error');
                console.error('Error:', error);
                showScreen('startScreen');
            }
        }

        // Play audio response
        function playAudioResponse(audioBlob, responseText) {
            showScreen('playingScreen');
            document.getElementById('responseText').textContent = responseText;
            
            const audioPlayer = document.getElementById('audioPlayer');
            const audioUrl = URL.createObjectURL(audioBlob);
            audioPlayer.src = audioUrl;
            
            audioPlayer.play();
            
            audioPlayer.onended = () => {
                console.log('Audio playback finished');
                URL.revokeObjectURL(audioUrl);
            };
            
            audioPlayer.onerror = (error) => {
                console.error('Audio playback error:', error);
                showStatus('Error playing audio', 'error');
            };
        }

        // Continue conversation
        document.getElementById('continueBtn').addEventListener('click', () => {
            showScreen('startScreen');
        });

        // End call buttons
        document.getElementById('endCallBtn').addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
            }
            showScreen('startScreen');
            showStatus('Call ended', 'info');
        });

        document.getElementById('endCallBtn2').addEventListener('click', () => {
            const audioPlayer = document.getElementById('audioPlayer');
            audioPlayer.pause();
            audioPlayer.currentTime = 0;
            showScreen('startScreen');
            showStatus('Call ended', 'info');
        });
    </script>
</body>
</html>
